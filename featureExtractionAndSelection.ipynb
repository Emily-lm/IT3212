{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data = pd.read_csv('preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the numerical features\n",
    "\n",
    "numerical_weather_features = [\n",
    "    'temp', 'humidity', 'wind_speed', 'pressure', 'clouds_all',\n",
    "    'rain_1h', 'rain_3h', 'snow_3h', 'visibility', 'wind_deg'\n",
    "]\n",
    "\n",
    "# Identify temperature-related columns (specific to weather data)\n",
    "temp_columns = [col for col in data.columns if 'temp_' in col]\n",
    "max_temp_columns = [col for col in temp_columns if 'temp_max' in col]\n",
    "min_temp_columns = [col for col in temp_columns if 'temp_min' in col]\n",
    "avg_temp_columns = [col for col in temp_columns if col not in max_temp_columns and col not in min_temp_columns]\n",
    "\n",
    "# Compute the average for 'temp', the max for 'temp_max', and the min for 'temp_min'\n",
    "data['avg_temp'] = data[avg_temp_columns].mean(axis=1)\n",
    "data['max_temp'] = data[max_temp_columns].max(axis=1)\n",
    "data['min_temp'] = data[min_temp_columns].min(axis=1)\n",
    "\n",
    "# Identify columns related to energy generation, forecasts, and prices\n",
    "generation_columns = [col for col in data.columns if 'generation' in col or 'forecast' in col or 'price' in col]\n",
    "\n",
    "# Average numerical weather features across cities\n",
    "for feature in numerical_weather_features:\n",
    "    # Identify all city-specific columns for this feature\n",
    "    city_specific_columns = [col for col in data.columns if col.startswith(feature + '_')]\n",
    "    \n",
    "    # Compute the average across cities\n",
    "    if city_specific_columns:\n",
    "        data[f'avg_{feature}'] = data[city_specific_columns].mean(axis=1)\n",
    "        \n",
    "        # Drop the original city-specific weather columns\n",
    "        data.drop(columns=city_specific_columns, inplace=True)\n",
    "\n",
    "# Drop the original temperature columns (excluding generation columns)\n",
    "columns_to_drop = [col for col in (avg_temp_columns + max_temp_columns + min_temp_columns) if col in data.columns and col not in generation_columns]\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Reorder the DataFrame: Place 'dt_iso', followed by averaged features, then the rest\n",
    "averaged_columns = [col for col in data.columns if col.startswith('avg_') or col in ['avg_temp', 'max_temp', 'min_temp']]\n",
    "columns_order = ['dt_iso'] + averaged_columns + [col for col in data.columns if col not in averaged_columns and col != 'dt_iso']\n",
    "data = data[columns_order]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time-based features from 'dt_iso'\n",
    "\n",
    "# Convert 'dt_iso' to datetime type with UTC handling\n",
    "data['dt_iso'] = pd.to_datetime(data['dt_iso'], utc=True, errors='coerce')\n",
    "\n",
    "# Extract time-based features\n",
    "data['hour_of_day'] = data['dt_iso'].dt.hour\n",
    "data['day_of_week'] = data['dt_iso'].dt.dayofweek\n",
    "data['month'] = data['dt_iso'].dt.month\n",
    "\n",
    "# Create lag features for 'total load actual'\n",
    "\n",
    "# 1-hour lag\n",
    "data['total_load_actual_lag_1'] = data['total load actual'].shift(1)\n",
    "\n",
    "# 12-hour lag\n",
    "data['total_load_actual_lag_12'] = data['total load actual'].shift(12)\n",
    "\n",
    "# 24-hour lag\n",
    "data['total_load_actual_lag_24'] = data['total load actual'].shift(24)\n",
    "\n",
    "# Drop the rows with NaN values due to lag creation\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Order Columns\n",
    "\n",
    "time_features = ['month', 'day_of_week', 'hour_of_day']\n",
    "averaged_features = [col for col in data.columns if col.startswith('avg_')]\n",
    "lag_features = [col for col in data.columns if 'lag' in col]\n",
    "other_columns = [col for col in data.columns if col not in ['dt_iso'] + time_features + averaged_features + lag_features]\n",
    "\n",
    "ordered_columns = ['dt_iso'] + time_features + averaged_features + other_columns + lag_features\n",
    "\n",
    "# Reorder the DataFrame\n",
    "data = data[ordered_columns]\n",
    "\n",
    "# Display the first few rows of the reordered DataFrame\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all boolean features (e.g., weather descriptions, icons)\n",
    "boolean_columns = [col for col in data.columns if 'weather_description_' in col or 'weather_icon_' in col or 'weather_main_' in col or 'weather_id_' in col]\n",
    "data = data.drop(columns=boolean_columns)\n",
    "\n",
    "# Compute the correlation matrix for numerical features\n",
    "numerical_data = data.select_dtypes(include='number')\n",
    "correlation_matrix = numerical_data.corr()\n",
    "\n",
    "# Set a high correlation threshold (absolute correlation > 0.9)\n",
    "high_corr_threshold = 0.9\n",
    "\n",
    "# Identify pairs of features with high correlation\n",
    "high_corr_pairs = [\n",
    "    (col1, col2) for col1 in correlation_matrix.columns for col2 in correlation_matrix.columns\n",
    "    if col1 != col2 and abs(correlation_matrix.loc[col1, col2]) > high_corr_threshold\n",
    "]\n",
    "\n",
    "# Plot the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0, linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix of Numerical Features (Without Boolean Features)\")\n",
    "plt.show()\n",
    "\n",
    "# Print the list of highly correlated feature pairs\n",
    "print(\"Highly correlated feature pairs (threshold > 0.9):\", high_corr_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop highly correlated features\n",
    "\n",
    "data = data.drop(columns=['min_temp', 'generation solar', 'generation wind onshore', 'total load forecast'])\n",
    "\n",
    "data.to_csv('final_features_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "\n",
    "X = data.drop(columns=['total load actual', 'dt_iso'])  # Exclude the target and timestamp\n",
    "y = data['total load actual']\n",
    "\n",
    "# Perform the time-based split, setting shuffle=False to maintain order\n",
    "# Split into training and temp (validation + test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# Now split the temp into validation and test sets (50% each of the remaining 30%)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Shape of the splits\n",
    "print(\"Training set shape (X_train, y_train):\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape (X_val, y_val):\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set shape (X_test, y_test):\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Save splits\n",
    "X_train.to_csv('train/X_train.csv', index=False)\n",
    "y_train.to_csv('train/y_train.csv', index=False)\n",
    "\n",
    "X_val.to_csv('validation/X_val.csv', index=False)\n",
    "y_val.to_csv('validation/y_val.csv', index=False)\n",
    "\n",
    "X_test.to_csv('test/X_test.csv', index=False)\n",
    "y_test.to_csv('test/y_test.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
