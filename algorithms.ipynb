{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#import catboost as cb\n",
    "#import lightgbm as lgb\n",
    "#import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"train/X_train.csv\")\n",
    "y_train = pd.read_csv(\"train/y_train.csv\")\n",
    "\n",
    "X_val = pd.read_csv(\"validation/X_val.csv\")\n",
    "y_val = pd.read_csv(\"validation/y_val.csv\")\n",
    "\n",
    "X_test = pd.read_csv(\"test/X_test.csv\")\n",
    "y_test = pd.read_csv(\"test/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = [1, 2, 3, 4]\n",
    "validation_errors = []\n",
    "best_degree=1\n",
    "\n",
    "\"\"\"for degree in degrees:\n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_val_poly = poly.transform(X_val)\n",
    "    \n",
    "    # Train a linear regression model on the polynomial features\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, y_train)\n",
    "    \n",
    "    # Predict on the validation set and calculate error\n",
    "    y_val_pred = model.predict(X_val_poly)\n",
    "    val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "    validation_errors.append(val_mse)\n",
    "    \n",
    "    print(f\"Degree: {degree}, Validation MSE: {val_mse}\")\n",
    "\n",
    "# Select the best polynomial degree based on the lowest validation error\n",
    "best_degree = degrees[np.argmin(validation_errors)]\n",
    "print(f\"Best Polynomial Degree: {best_degree}\")\"\"\"\n",
    "\n",
    "# Combine training and validation sets\n",
    "X_train_val = pd.concat([X_train, X_val])\n",
    "y_train_val = pd.concat([y_train, y_val])\n",
    "\n",
    "# Create polynomial features with the best degree\n",
    "poly = PolynomialFeatures(degree=best_degree)\n",
    "X_train_val_poly = poly.fit_transform(X_train_val)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# Train the model on the combined training and validation set\n",
    "final_model = LinearRegression()\n",
    "final_model.fit(X_train_val_poly, y_train_val)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = final_model.predict(X_test_poly)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "print(f\"Test Mean Squared Error: {test_mse}\")\n",
    "print(f\"Test R^2: {test_r2}\")\n",
    "\n",
    "# Plot actual vs predicted values for the test set\n",
    "plt.plot(range(len(y_test)), y_test, label=\"Actual Values\")\n",
    "plt.plot(range(len(y_test_pred)), y_test_pred, label=\"Predicted Values\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time Steps (Test Data)\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neural network\n",
    "model = MLPRegressor(hidden_layer_sizes=(10,), max_iter=2000, random_state=0)\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Squared Error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R^2: {r2}\")\n",
    "\n",
    "# Plot actual vs predicted values for the test set\n",
    "plt.plot(range(len(y_test)), y_test, label=\"Actual Values\")\n",
    "plt.plot(range(len(y_pred)), y_pred, label=\"Predicted Values\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time Steps (Test Data)\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree regressor\n",
    "model_dt = DecisionTreeRegressor(random_state=42)\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "print(f\"Mean Squared Error Decision Tree: {mse_dt}\")\n",
    "print(f\"R^2 Decision Tree: {r2_dt}\")\n",
    "\n",
    "plt.plot(range(len(y_test)), y_test, label=\"Actual Values\")\n",
    "plt.plot(range(len(y_pred_dt)), y_pred_dt, label=\"Predicted Values\")\n",
    "plt.legend()\n",
    "plt.title(\"Decision Tree Regressor\")\n",
    "plt.xlabel(\"Time Steps (Test Data)\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestRegressor(random_state=42)\n",
    "model_rf.fit(X_train, y_train, )\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "print(f\"Mean Squared Error Random Forest: {mse_rf}\")\n",
    "print(f\"R^2 Random Forest: {r2_rf}\")\n",
    "\n",
    "plt.plot(range(len(y_test)), y_test, label=\"Actual Values\")\n",
    "plt.plot(range(len(y_pred_rf)), y_pred_rf, label=\"Predicted Values\")\n",
    "plt.legend()\n",
    "plt.title(\"Random Forest\")\n",
    "plt.xlabel(\"Time Steps (Test Data)\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM with kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM regressor (Support Vector Machine)\n",
    "from sklearn.svm import SVR\n",
    "model_svm = SVR()\n",
    "model_svm.fit(X_train, y_train)\n",
    "y_pred_svm = model_svm.predict(X_test)\n",
    "\n",
    "mse_svm = mean_squared_error(y_test, y_pred_svm)\n",
    "r2_svm = r2_score(y_test, y_pred_svm)\n",
    "print(f\"Mean Squared Error SVM: {mse_svm}\")\n",
    "print(f\"R^2 SVM: {r2_svm}\")\n",
    "\n",
    "plt.plot(range(len(y_test)), y_test, label=\"Actual Values\")\n",
    "plt.plot(range(len(y_pred_svm)), y_pred_svm, label=\"Predicted Values\")\n",
    "plt.legend()\n",
    "plt.title(\"Support Vector Machine\")\n",
    "plt.xlabel(\"Time Steps (Test Data)\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additive model gam \n",
    "from pygam import LinearGAM, s\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "terms = [s(i) for i in range(n_features)]\n",
    "terms = s(0) + s(1) + s(2) + s(3) + s(4) + s(5) + s(6) + s(7) + s(8) + s(9) + s(10) + s(11) + s(12) + s(13) + s(14) + s(15) + s(16) + s(17) + s(18) + s(19) + s(20) + s(21) + s(22) + s(23) + s(24) + s(25) + s(26) + s(27) + s(28) + s(29) + s(30) + s(31) + s(32) + s(33) + s(34) \n",
    "model_gam = LinearGAM(terms)\n",
    "model_gam.fit(X_train, y_train)\n",
    "y_pred_gam = model_gam.predict(X_test)\n",
    "\n",
    "mse_gam = mean_squared_error(y_test, y_pred_gam)\n",
    "r2_gam = r2_score(y_test, y_pred_gam)\n",
    "\n",
    "print(f\"Mean Squared Error GAM: {mse_gam}\")\n",
    "print(f\"R^2 GAM: {r2_gam}\")\n",
    "\n",
    "plt.plot(range(len(y_test)), y_test, label=\"Actual Values\")\n",
    "plt.plot(range(len(y_pred_gam)), y_pred_gam, label=\"Predicted Values\")\n",
    "plt.legend()\n",
    "plt.title(\"Generalized Additive Model\")\n",
    "plt.xlabel(\"Time Steps (Test Data)\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvvv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
