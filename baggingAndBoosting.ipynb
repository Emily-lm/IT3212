{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set seaborn style for better aesthetics\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X_train = pd.read_csv('train/X_train.csv')\n",
    "y_train = pd.read_csv('train/y_train.csv').squeeze()  \n",
    "\n",
    "X_val = pd.read_csv('validation/X_val.csv')\n",
    "y_val = pd.read_csv('validation/y_val.csv').squeeze()\n",
    "\n",
    "X_test = pd.read_csv('test/X_test.csv')\n",
    "y_test = pd.read_csv('test/y_test.csv').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, model_name=\"Model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"=== {model_name} Evaluation ===\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R² Score: {r2:.4f}\\n\")\n",
    "    \n",
    "    return mae, mse, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Utilize all available cores\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "rf_regressor.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on validation set\n",
    "y_val_pred_rf = rf_regressor.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate\n",
    "rf_val_mae, rf_val_mse, rf_val_rmse, rf_val_r2 = evaluate_model(y_val, y_val_pred_rf, model_name=\"Random Forest (Bagging)\")\n",
    "\n",
    "# Initialize the Gradient Boosting Regressor\n",
    "gb_regressor = GradientBoostingRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "gb_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Gradient Boosting Regressor Trained.\")\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred_gb = gb_regressor.predict(X_val_scaled)\n",
    "\n",
    "# Evaluate\n",
    "gb_val_mae, gb_val_mse, gb_val_rmse, gb_val_r2 = evaluate_model(y_val, y_val_pred_gb, model_name=\"Gradient Boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate models on the test set\n",
    "# Random Forest on Test Set\n",
    "y_test_pred_rf = rf_regressor.predict(X_test_scaled)\n",
    "rf_test_mae, rf_test_mse, rf_test_rmse, rf_test_r2 = evaluate_model(y_test, y_test_pred_rf, model_name=\"Random Forest on Test Set\")\n",
    "\n",
    "# Gradient Boosting on Test Set\n",
    "y_test_pred_gb = gb_regressor.predict(X_test_scaled)\n",
    "gb_test_mae, gb_test_mse, gb_test_rmse, gb_test_r2 = evaluate_model(y_test, y_test_pred_gb, model_name=\"Gradient Boosting on Test Set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the results\n",
    "results = {\n",
    "    'Model': ['Random Forest', 'Gradient Boosting'],\n",
    "    'Validation MAE': [rf_val_mae, gb_val_mae],\n",
    "    'Validation MSE': [rf_val_mse, gb_val_mse],\n",
    "    'Validation RMSE': [rf_val_rmse, gb_val_rmse],\n",
    "    'Validation R² Score': [rf_val_r2, gb_val_r2],\n",
    "    'Test MAE': [rf_test_mae, gb_test_mae],\n",
    "    'Test MSE': [rf_test_mse, gb_test_mse],\n",
    "    'Test RMSE': [rf_test_rmse, gb_test_rmse],\n",
    "    'Test R² Score': [rf_test_r2, gb_test_r2]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Evaluation Results:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Validation Metrics\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot MAE and RMSE for Validation Set\n",
    "metrics = ['Validation MAE', 'Validation RMSE']\n",
    "for i, metric in enumerate(metrics):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    sns.barplot(x='Model', y=metric, data=results_df)\n",
    "    plt.title(f'Comparison of {metric}')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Model')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization of R² Score for Validation Set\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.barplot(x='Model', y='Validation R² Score', data=results_df)\n",
    "plt.title('Comparison of Validation R² Score')\n",
    "plt.ylabel('R² Score')\n",
    "plt.xlabel('Model')\n",
    "plt.show()\n",
    "\n",
    "# Visualization of Test Metrics\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot MAE and RMSE for Test Set\n",
    "test_metrics = ['Test MAE', 'Test RMSE']\n",
    "for i, metric in enumerate(test_metrics):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    sns.barplot(x='Model', y=metric, data=results_df)\n",
    "    plt.title(f'Comparison of {metric}')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Model')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization of R² Score for Test Set\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.barplot(x='Model', y='Test R² Score', data=results_df)\n",
    "plt.title('Comparison of Test R² Score')\n",
    "plt.ylabel('R² Score')\n",
    "plt.xlabel('Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importances for Random Forest\n",
    "importances_rf = rf_regressor.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a DataFrame\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances_rf\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_rf.head(20))\n",
    "plt.title('Top 20 Feature Importances - Random Forest')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature Importances for Gradient Boosting\n",
    "importances_gb = gb_regressor.feature_importances_\n",
    "\n",
    "# Create a DataFrame\n",
    "feature_importance_gb = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances_gb\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_gb.head(20))\n",
    "plt.title('Top 20 Feature Importances - Gradient Boosting')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Predicted vs. Actual Scatter Plots\n",
    "def plot_predicted_vs_actual(y_true, y_pred, model_name, dataset_type=\"Validation\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=y_true, y=y_pred, alpha=0.5)\n",
    "    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')  # Diagonal line\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'{model_name} - {dataset_type} Set: Predicted vs. Actual')\n",
    "    plt.show()\n",
    "\n",
    "# Random Forest - Validation Set\n",
    "plot_predicted_vs_actual(y_val, y_val_pred_rf, \"Random Forest\", \"Validation\")\n",
    "\n",
    "# Gradient Boosting - Validation Set\n",
    "plot_predicted_vs_actual(y_val, y_val_pred_gb, \"Gradient Boosting\", \"Validation\")\n",
    "\n",
    "# Random Forest - Test Set\n",
    "plot_predicted_vs_actual(y_test, y_test_pred_rf, \"Random Forest\", \"Test\")\n",
    "\n",
    "# Gradient Boosting - Test Set\n",
    "plot_predicted_vs_actual(y_test, y_test_pred_gb, \"Gradient Boosting\", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Residual Plots\n",
    "def plot_residuals(y_true, y_pred, model_name, dataset_type=\"Validation\"):\n",
    "    residuals = y_true - y_pred\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=y_pred, y=residuals, alpha=0.5)\n",
    "    plt.axhline(0, color='r', linestyle='--')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.title(f'{model_name} - {dataset_type} Set: Residuals')\n",
    "    plt.show()\n",
    "\n",
    "# Random Forest - Validation Set\n",
    "plot_residuals(y_val, y_val_pred_rf, \"Random Forest\", \"Validation\")\n",
    "\n",
    "# Gradient Boosting - Validation Set\n",
    "plot_residuals(y_val, y_val_pred_gb, \"Gradient Boosting\", \"Validation\")\n",
    "\n",
    "# Random Forest - Test Set\n",
    "plot_residuals(y_test, y_test_pred_rf, \"Random Forest\", \"Test\")\n",
    "\n",
    "# Gradient Boosting - Test Set\n",
    "plot_residuals(y_test, y_test_pred_gb, \"Gradient Boosting\", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Error Distribution Histograms\n",
    "def plot_error_distribution(y_true, y_pred, model_name, dataset_type=\"Validation\"):\n",
    "    errors = y_true - y_pred\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(errors, bins=30, kde=True)\n",
    "    plt.xlabel('Error')\n",
    "    plt.title(f'{model_name} - {dataset_type} Set: Error Distribution')\n",
    "    plt.show()\n",
    "\n",
    "# Random Forest - Validation Set\n",
    "plot_error_distribution(y_val, y_val_pred_rf, \"Random Forest\", \"Validation\")\n",
    "\n",
    "# Gradient Boosting - Validation Set\n",
    "plot_error_distribution(y_val, y_val_pred_gb, \"Gradient Boosting\", \"Validation\")\n",
    "\n",
    "# Random Forest - Test Set\n",
    "plot_error_distribution(y_test, y_test_pred_rf, \"Random Forest\", \"Test\")\n",
    "\n",
    "# Gradient Boosting - Test Set\n",
    "plot_error_distribution(y_test, y_test_pred_gb, \"Gradient Boosting\", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Correlation Heatmap\n",
    "def plot_correlation_heatmap(df, title=\"Correlation Heatmap\"):\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    corr = df.corr()\n",
    "    sns.heatmap(corr, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Combine training features with target for correlation\n",
    "train_data = pd.concat([X_train, y_train.rename('Target')], axis=1)\n",
    "\n",
    "plot_correlation_heatmap(train_data, \"Feature Correlation Heatmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Pair Plots (selecting a subset of features for clarity)\n",
    "def plot_pairwise_relationships(df, features, target):\n",
    "    sns.pairplot(df[features + [target]], diag_kind='kde', kind='scatter', corner=True)\n",
    "    plt.suptitle('Pairwise Feature Relationships', y=1.02)\n",
    "    plt.show()\n",
    "\n",
    "# Select top 5 features based on Random Forest importance\n",
    "top5_features_rf = feature_importance_rf['Feature'].head(5).tolist()\n",
    "\n",
    "plot_pairwise_relationships(train_data, top5_features_rf, 'Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Actual vs. Predicted with Regression Line\n",
    "def plot_actual_vs_predicted_regression(y_true, y_pred, model_name, dataset_type=\"Validation\"):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.regplot(\n",
    "        x=y_true, \n",
    "        y=y_pred, \n",
    "        scatter_kws={'alpha': 0.5},  # Corrected from 'scatter_k' to 'scatter_kws'\n",
    "        line_kws={\"color\": \"red\"}, \n",
    "        fit_reg=True  # You can also use 'reg=True' if 'fit_reg' is deprecated\n",
    "    )\n",
    "    plt.xlabel('Actual Values')\n",
    "    plt.ylabel('Predicted Values')\n",
    "    plt.title(f'{model_name} - {dataset_type} Set: Actual vs. Predicted with Regression Line')\n",
    "    plt.show()\n",
    "\n",
    "# Random Forest - Validation Set\n",
    "plot_actual_vs_predicted_regression(y_val, y_val_pred_rf, \"Random Forest\", \"Validation\")\n",
    "\n",
    "# Gradient Boosting - Validation Set\n",
    "plot_actual_vs_predicted_regression(y_val, y_val_pred_gb, \"Gradient Boosting\", \"Validation\")\n",
    "\n",
    "# Random Forest - Test Set\n",
    "plot_actual_vs_predicted_regression(y_test, y_test_pred_rf, \"Random Forest\", \"Test\")\n",
    "\n",
    "# Gradient Boosting - Test Set\n",
    "plot_actual_vs_predicted_regression(y_test, y_test_pred_gb, \"Gradient Boosting\", \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Box Plots of Errors by Model\n",
    "def plot_error_boxplots(y_true_rf, y_pred_rf, y_true_gb, y_pred_gb, dataset_type=\"Validation\"):\n",
    "    errors_rf = y_true_rf - y_pred_rf\n",
    "    errors_gb = y_true_gb - y_pred_gb\n",
    "    errors_df = pd.DataFrame({\n",
    "        'Random Forest': errors_rf,\n",
    "        'Gradient Boosting': errors_gb\n",
    "    })\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=errors_df)\n",
    "    plt.title(f'Error Distribution by Model - {dataset_type} Set')\n",
    "    plt.ylabel('Error')\n",
    "    plt.show()\n",
    "\n",
    "# Box Plots for Validation Set\n",
    "plot_error_boxplots(y_val, y_val_pred_rf, y_val, y_val_pred_gb, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box Plots for Test Set\n",
    "plot_error_boxplots(y_test, y_test_pred_rf, y_test, y_test_pred_gb, \"Test\")\n",
    "\n",
    "# 8. Violin Plots of Errors by Model\n",
    "def plot_error_violinplots(y_true_rf, y_pred_rf, y_true_gb, y_pred_gb, dataset_type=\"Validation\"):\n",
    "    errors_rf = y_true_rf - y_pred_rf\n",
    "    errors_gb = y_true_gb - y_pred_gb\n",
    "    errors_df = pd.DataFrame({\n",
    "        'Random Forest': errors_rf,\n",
    "        'Gradient Boosting': errors_gb\n",
    "    })\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(data=errors_df)\n",
    "    plt.title(f'Error Distribution by Model - {dataset_type} Set')\n",
    "    plt.ylabel('Error')\n",
    "    plt.show()\n",
    "\n",
    "# Violin Plots for Validation Set\n",
    "plot_error_violinplots(y_val, y_val_pred_rf, y_val, y_val_pred_gb, \"Validation\")\n",
    "\n",
    "# Violin Plots for Test Set\n",
    "plot_error_violinplots(y_test, y_test_pred_rf, y_test, y_test_pred_gb, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Partial Dependence Plots (PDP) for Top Features\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "def plot_partial_dependence(estimator, X, features, feature_names, model_name):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    PartialDependenceDisplay.from_estimator(estimator, X, features, feature_names=feature_names, grid_resolution=20)\n",
    "    plt.suptitle(f'Partial Dependence Plots - {model_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Select top 3 features for PDP\n",
    "top3_features_rf = feature_importance_rf['Feature'].head(3).tolist()\n",
    "top3_features_gb = feature_importance_gb['Feature'].head(3).tolist()\n",
    "\n",
    "# Plot PDP for Random Forest\n",
    "plot_partial_dependence(rf_regressor, X_train_scaled, top3_features_rf, feature_names, \"Random Forest\")\n",
    "\n",
    "# Plot PDP for Gradient Boosting\n",
    "plot_partial_dependence(gb_regressor, X_train_scaled, top3_features_gb, feature_names, \"Gradient Boosting\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
