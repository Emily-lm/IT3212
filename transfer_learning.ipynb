{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "data_large = pd.read_csv('household_power_consumption.txt', sep=';', \n",
    "                         parse_dates={'Datetime': ['Date', 'Time']}, \n",
    "                         infer_datetime_format=True, \n",
    "                         low_memory=False, na_values=['nan','?'])\n",
    "\n",
    "cols_to_numeric = ['Global_active_power', 'Global_reactive_power', 'Voltage', \n",
    "                   'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "for col in cols_to_numeric:\n",
    "    data_large[col] = pd.to_numeric(data_large[col], errors='coerce')\n",
    "\n",
    "data_large.dropna(inplace=True)\n",
    "\n",
    "data_large['Hour'] = data_large['Datetime'].dt.hour\n",
    "data_large['Day'] = data_large['Datetime'].dt.dayofweek\n",
    "data_large['Month'] = data_large['Datetime'].dt.month\n",
    "\n",
    "data_large.sort_values('Datetime', inplace=True)\n",
    "\n",
    "data_large['Target'] = data_large['Global_active_power'].shift(-1440)\n",
    "data_large.dropna(subset=['Target'], inplace=True)\n",
    "\n",
    "features_large = data_large[['Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', \n",
    "                             'Sub_metering_2', 'Sub_metering_3', 'Hour', 'Day', 'Month']]\n",
    "target_large = data_large['Target']\n",
    "\n",
    "X_train_large, X_test_large, y_train_large, y_test_large = train_test_split(\n",
    "    features_large, target_large, test_size=0.2, shuffle=False)\n",
    "\n",
    "scaler_large = StandardScaler()\n",
    "X_train_large = scaler_large.fit_transform(X_train_large)\n",
    "X_test_large = scaler_large.transform(X_test_large)\n",
    "\n",
    "model_large = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_large.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_large.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model_large.fit(X_train_large, y_train_large, epochs=5, batch_size=128, validation_split=0.1)\n",
    "\n",
    "weather_data = pd.read_csv(\"spanish-cities-energy-consumption/weather_features.csv\")\n",
    "energy_data = pd.read_csv(\"spanish-cities-energy-consumption/energy_dataset.csv\")\n",
    "\n",
    "energy_data.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "weather_data['dt_iso'] = pd.to_datetime(weather_data['dt_iso'], utc=True).dt.tz_localize(None)\n",
    "energy_data['time'] = pd.to_datetime(energy_data['time'], utc=True).dt.tz_localize(None)\n",
    "\n",
    "weather_data.dropna(subset=['dt_iso'], inplace=True)\n",
    "energy_data.dropna(subset=['time'], inplace=True)\n",
    "\n",
    "weather_data.sort_values('dt_iso', inplace=True)\n",
    "energy_data.sort_values('time', inplace=True)\n",
    "\n",
    "data_small = pd.merge_asof(weather_data,\n",
    "                           energy_data,\n",
    "                           left_on='dt_iso',\n",
    "                           right_on='time',\n",
    "                           direction='nearest')\n",
    "\n",
    "data_small.sort_values('dt_iso', inplace=True)\n",
    "data_small['Target'] = data_small['total load actual'].shift(-24)\n",
    "data_small.dropna(subset=['Target'], inplace=True)\n",
    "\n",
    "data_small['Hour'] = data_small['dt_iso'].dt.hour\n",
    "data_small['Day'] = data_small['dt_iso'].dt.dayofweek\n",
    "data_small['Month'] = data_small['dt_iso'].dt.month\n",
    "\n",
    "features_small = data_small[['Hour', 'Day', 'Month']]\n",
    "\n",
    "missing_features = [col for col in features_large.columns if col not in features_small.columns]\n",
    "for col in missing_features:\n",
    "    features_small[col] = 0\n",
    "\n",
    "features_small = features_small[features_large.columns]\n",
    "target_small = data_small['Target']\n",
    "\n",
    "X_small = scaler_large.transform(features_small)\n",
    "y_small = target_small.values\n",
    "\n",
    "model_large.compile(optimizer=Adam(learning_rate=0.0001), loss='mean_squared_error')\n",
    "\n",
    "split_index = int(len(X_small) * 0.8)\n",
    "X_train_small, X_val_small = X_small[:split_index], X_small[split_index:]\n",
    "y_train_small, y_val_small = y_small[:split_index], y_small[split_index:]\n",
    "\n",
    "model_large.fit(X_train_small, y_train_small, epochs=5, batch_size=64, validation_data=(X_val_small, y_val_small))\n",
    "\n",
    "y_pred_small = model_large.predict(X_val_small)\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mse, rmse, mae, r2\n",
    "\n",
    "metrics_transfer = calculate_metrics(y_val_small, y_pred_small)\n",
    "\n",
    "print(f\"Transfer Learning Model MSE: {metrics_transfer[0]}\")\n",
    "print(f\"Transfer Learning Model RMSE: {metrics_transfer[1]}\")\n",
    "print(f\"Transfer Learning Model MAE: {metrics_transfer[2]}\")\n",
    "print(f\"Transfer Learning Model R2: {metrics_transfer[3]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
