{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10278/2614862819.py:17: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  image_array = np.array(image, dtype=np.float32)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.87 PiB for an array with shape (20113920, 20113920) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Perform PCA, select top k principal components (e.g., k=2)\u001b[39;00m\n\u001b[1;32m     68\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m---> 69\u001b[0m projected_images, principal_components \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# Plot the original normalized images\u001b[39;00m\n\u001b[1;32m     72\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(normalized_images), figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n",
      "Cell \u001b[0;32mIn[6], line 35\u001b[0m, in \u001b[0;36mpca\u001b[0;34m(images, k)\u001b[0m\n\u001b[1;32m     32\u001b[0m centered_images \u001b[38;5;241m=\u001b[39m images \u001b[38;5;241m-\u001b[39m mean_image\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Step 3: Compute the covariance matrix\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m covariance_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcentered_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Step 4: Compute the eigenvalues and eigenvectors of the covariance matrix\u001b[39;00m\n\u001b[1;32m     38\u001b[0m eigenvalues, eigenvectors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigh(covariance_matrix)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/_function_base_impl.py:2847\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2846\u001b[0m     X_T \u001b[38;5;241m=\u001b[39m (X\u001b[38;5;241m*\u001b[39mw)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m-> 2847\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_T\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2848\u001b[0m c \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtrue_divide(\u001b[38;5;241m1\u001b[39m, fact)\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 2.87 PiB for an array with shape (20113920, 20113920) and data type float64"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "data = pd.read_csv(\"facial-emotion-recognition/facial-emotion-recognition-dataset.csv\", sep=\";\")\n",
    "image_dir = 'facial-emotion-recognition/images'\n",
    "\n",
    "\n",
    "\n",
    "def normalize_image(image_path):\n",
    "    image = Image.open(image_path).convert('L')  # Convert to grayscale\n",
    "    image_array = np.array(image, dtype=np.float32)\n",
    "    normalized_image = image_array / 255.0  # Normalize pixel values\n",
    "    return normalized_image\n",
    "\n",
    "# Convert images into a 2D matrix where each row represents a flattened image\n",
    "def images_to_matrix(image_list):\n",
    "    flattened_images = [img.flatten() for img in image_list]\n",
    "    return np.array(flattened_images)\n",
    "\n",
    "# PCA using Singular Value Decomposition (SVD)\n",
    "def pca_svd(images, k):\n",
    "    # Step 1: Compute the mean image\n",
    "    mean_image = np.mean(images, axis=0)\n",
    "    \n",
    "    # Step 2: Subtract the mean image from all images (mean normalization)\n",
    "    centered_images = images - mean_image\n",
    "    \n",
    "    # Step 3: Perform SVD\n",
    "    U, S, Vt = np.linalg.svd(centered_images, full_matrices=False)\n",
    "    \n",
    "    # Step 4: Select the top k components (eigenvectors)\n",
    "    principal_components = Vt[:k]\n",
    "    \n",
    "    # Step 5: Project the original images onto the principal components\n",
    "    projected_images = np.dot(centered_images, principal_components.T)\n",
    "    \n",
    "    return projected_images, principal_components\n",
    "\n",
    "# Set up the data\n",
    "sample_set_id = 0\n",
    "emotion_images = ['Anger.jpg', 'Contempt.jpg', 'Disgust.jpg', 'Fear.jpg', 'Happy.jpg', 'Neutral.jpg', 'Sad.jpg', 'Surprised.jpg']\n",
    "image_dir = 'facial-emotion-recognition/images'\n",
    "\n",
    "# Load and normalize the images\n",
    "normalized_images = []\n",
    "for emotion in emotion_images:\n",
    "    image_path = os.path.join(image_dir, f\"{sample_set_id}\", emotion)\n",
    "    normalized_img = normalize_image(image_path)\n",
    "    normalized_images.append(normalized_img)\n",
    "\n",
    "# Convert the list of images into a 2D matrix (where each row is a flattened image)\n",
    "image_matrix = images_to_matrix(normalized_images)\n",
    "\n",
    "# Perform PCA using SVD, select top k principal components (e.g., k=2)\n",
    "k = 2\n",
    "projected_images, principal_components = pca_svd(image_matrix, k)\n",
    "\n",
    "# Plot the original normalized images\n",
    "fig, axes = plt.subplots(1, len(normalized_images), figsize=(12, 4))\n",
    "for i, img in enumerate(normalized_images):\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(emotion_images[i])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Visualize the projected images onto the first two principal components\n",
    "plt.scatter(projected_images[:, 0], projected_images[:, 1], c='b', marker='o')\n",
    "plt.title(\"Images Projected onto First Two Principal Components\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
